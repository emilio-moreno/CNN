{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea456a5-d924-4728-b497-5280bd9ddc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "9702f010-f2a6-4a9f-9718-e87e97b1231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "\n",
    "    @np.vectorize\n",
    "    @staticmethod\n",
    "    def activation_function(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    \n",
    "    @np.vectorize\n",
    "    @staticmethod\n",
    "    def activation_derivative(z):\n",
    "        return np.exp(z) / (np.exp(z) + np.exp(-z))**2\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def cost(a, y):\n",
    "        return 0.5 * np.dot(np.transpose(a - y), a - y)[0][0]\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def cost_gradient(a, y):\n",
    "        # There's an incorrect sign somewhere but I can't find it.\n",
    "        return a - y\n",
    "    \n",
    "\n",
    "    def __init__(self, dim: list):\n",
    "        self.dim = [dim[0]] + dim[1] + [dim[2]]\n",
    "        self.dim_input = dim[0]\n",
    "        self.dim_hidden = dim[1]\n",
    "        self.dim_output = dim[2]\n",
    "        self.weights = [np.random.normal(0, 1, (j, i)) for i, j in zip(self.dim[:-1], self.dim[1:])]\n",
    "        self.biases = [np.random.normal(0, 1, (i, 1)) for i in self.dim[1:]]\n",
    "\n",
    "    \n",
    "    def front_propagate(self, x):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            x = self.activation_function(np.dot(w, x) + b)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def calculate_inputs(self, x):\n",
    "        Z = [x]\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            x = np.dot(w, x) + b\n",
    "            Z.append(x)\n",
    "        return Z\n",
    "\n",
    "    \n",
    "    def calculate_neurons(self, x):\n",
    "        # I think in the end the first layer wasn't required. I'll maybe change it later.\n",
    "        # If I change it here, I'll need to move the indices in backpropagate.\n",
    "        A = [x]\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            x = self.activation_function(np.dot(w, x) + b)\n",
    "            A.append(x)\n",
    "        return A\n",
    "\n",
    "    \n",
    "    def backpropagate(self, x, y):\n",
    "        inputs = self.calculate_inputs(x)\n",
    "        neurons = self.calculate_neurons(x)\n",
    "        grad_C = self.cost_gradient(neurons[-1], y)\n",
    "        errors = [np.multiply(grad_C, inputs[-1])]\n",
    "\n",
    "        for z, W in zip(inputs[-2:0:-1], self.weights[:0:-1]):\n",
    "            error = np.multiply(np.dot(np.transpose(W), errors[-1]),\n",
    "                                self.activation_derivative(z))\n",
    "            errors.append(error)\n",
    "        errors.reverse()\n",
    "        weight_partials = []\n",
    "        for e, a in zip(errors, neurons):\n",
    "            weight_partials.append(np.dot(e, np.transpose(a)))\n",
    "\n",
    "        return weight_partials, errors\n",
    "\n",
    "\n",
    "\n",
    "    def update(self, weight_partials, bias_partials):\n",
    "        new_weights = []\n",
    "        new_biases = []\n",
    "        for w, b, wp, bp in zip(self.weights, self.biases, weight_partials, bias_partials):\n",
    "            new_weights.append(w - wp)\n",
    "            new_biases.append(b - bp)\n",
    "\n",
    "        self.weights = new_weights\n",
    "        self.biases = new_biases\n",
    "            \n",
    "        \n",
    "\n",
    "    def SGD(self, U, epochs, lr=1E-3, MB_size=50, train_ratio=0.9):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        U: array-like\n",
    "            list of tuples containing input-output pairs (x, y).\n",
    "        '''\n",
    "        j = int(len(U) * train_ratio)\n",
    "        train_U = U[0:j]\n",
    "        test_U = U[j:]\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            np.random.shuffle(train_U)\n",
    "            \n",
    "            for i in range(int(np.ceil(len(train_U) / MB_size))):\n",
    "                minibatch = train_U[i * MB_size:(i+1) * MB_size]\n",
    "                weight_partials = len(self.weights) * [0]\n",
    "                bias_partials = len(self.weights) * [0]\n",
    "                for x, y in minibatch:\n",
    "                    wp, bp = self.backpropagate(x, y)\n",
    "                    weight_partials = [a - lr * b / len(minibatch) for a, b in zip(weight_partials, wp)]\n",
    "                    bias_partials = [a - lr * b / len(minibatch) for a, b in zip(bias_partials, bp)]            \n",
    "            self.update(weight_partials, bias_partials)\n",
    "            \n",
    "            test_cost = 0\n",
    "            for x, y in test_U:\n",
    "                test_cost += self.cost(self.front_propagate(x), y) / len(test_U)\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"{epoch = }, {test_cost = }\")\n",
    "\n",
    "    \n",
    "    def print_parameters(self):\n",
    "        weights = [w.shape for w in self.weights]\n",
    "        biases = [b.shape for b in self.biases]\n",
    "        print(f\"dimension = {self.dim}, {weights = }, {biases = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "37215de1-1256-4244-9d87-f63f7e434392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension = [3, 5, 10, 12, 3], weights = [(5, 3), (10, 5), (12, 10), (3, 12)], biases = [(5, 1), (10, 1), (12, 1), (3, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65755991],\n",
       "       [0.67933132],\n",
       "       [0.87978686]])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "dim = [3, [5, 10, 12], 3]\n",
    "net = Network(dim)\n",
    "net.print_parameters()\n",
    "net.front_propagate(np.random.uniform(0, 1, (3, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "66816cfb-9587-40ff-8307-02f8aeec23ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, test_cost = np.float64(0.019645264061833943)\n",
      "epoch = 10, test_cost = np.float64(0.013317415185250476)\n",
      "epoch = 20, test_cost = np.float64(0.009724061280893499)\n",
      "epoch = 30, test_cost = np.float64(0.007327044707847312)\n",
      "epoch = 40, test_cost = np.float64(0.005899436413211777)\n",
      "epoch = 50, test_cost = np.float64(0.004896492805929875)\n",
      "epoch = 60, test_cost = np.float64(0.004206439853955422)\n",
      "epoch = 70, test_cost = np.float64(0.003652995627938199)\n",
      "epoch = 80, test_cost = np.float64(0.003260807685247638)\n",
      "epoch = 90, test_cost = np.float64(0.0029649711880085365)\n"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "epochs = 100\n",
    "data = [(np.random.uniform(0, 1, (3, 1)), np.transpose(np.array([[0.5, 0.5, 0.5]]))) for _ in range(n)]\n",
    "net.SGD(data, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "372ad834-5eae-4d2e-a63c-3988a2ee3ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6046406 ],\n",
       "       [0.61035728],\n",
       "       [0.6714795 ]])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.front_propagate(np.random.uniform(0, 1, (3, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322baf68-9d08-45f5-ad29-74f1886f1218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
